{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM0m19dkKxh4CpudB6Oran",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StaniszewskiA/Loss-Functions/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmOwr2HSRHl1",
        "outputId": "8b56d48a-c338-4223-edc1-4bf66b5cc9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from typing import Dict\n",
        "import torch\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "def get_config_cnnh_cifar():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    config = {\n",
        "        \"T\": 30,\n",
        "        \"hash_save_path\": \"save/CNNH/\",\n",
        "        \"optimizer\": {\n",
        "            \"type\": optim.Adam,\n",
        "            \"optim_params\": {\n",
        "                \"lr\": 1e-4,\n",
        "                \"betas\": (0.9, 0.999)\n",
        "            }\n",
        "        },\n",
        "        \"info\": \"[CNNH]\",\n",
        "        \"resize_size\": 64,\n",
        "        \"crop_size\": 32,\n",
        "        \"batch_size\": 8,\n",
        "        \"net\": \"ResNet\",\n",
        "        \"dataset\": \"cifar\",\n",
        "        \"epochs\": 100,\n",
        "        \"save_interval\": 10,\n",
        "        \"test_MAP\": 10,\n",
        "        \"device\": device,\n",
        "        \"bit_list\": [12],\n",
        "    }\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(cifar_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "bits = 12\n",
        "n = 10000\n",
        "train_labels = torch.tensor([], dtype=torch.long)\n",
        "\n",
        "for data, labels in train_loader:\n",
        "    train_labels = torch.cat((train_labels, labels), dim=0)\n",
        "\n",
        "train_labels_capped = train_labels[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "      def __init__(self, hash_bits: int, pretrained: bool = True):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        model_alexnet = models.alexnet(pretrained=pretrained)\n",
        "        self.features = model_alexnet.features\n",
        "\n",
        "        self.hash_layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, hash_bits),\n",
        "        )\n",
        "\n",
        "      def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        hash_code = self.hash_layer(x)\n",
        "        return hash_code"
      ],
      "metadata": {
        "id": "l9mgy9Sn4w2e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"ResNet for Hashing\"\"\"\n",
        "    def __init__(self, hash_bits: int, pretrained: bool = True):\n",
        "        \"\"\"Constructor\"\"\"\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        model_resnet = models.resnet18(pretrained=pretrained)\n",
        "        self.features = nn.Sequential(*list(model_resnet.children())[:-1])\n",
        "\n",
        "        self.hash_layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(model_resnet.fc.in_features, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, hash_bits),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass\"\"\"\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        hash_code = self.hash_layer(x)\n",
        "        return hash_code"
      ],
      "metadata": {
        "id": "_KLqoMSC5TD0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_hash(n, bits):\n",
        "  hashes = 2 * torch.rand((n, bits)) - 1\n",
        "  return hashes"
      ],
      "metadata": {
        "id": "RsdqxzaX35lJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def initalize_sim_matrix(bits):\n",
        "  sim_matrix = np.outer(train_labels_capped, train_labels_capped)\n",
        "\n",
        "  sim_matrix_scaled = np.kron(sim_matrix, np.ones((bits, bits)))\n",
        "\n",
        "  return sim_matrix_scaled"
      ],
      "metadata": {
        "id": "NF84mqeL9pTG"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_hash_matrix(hash):\n",
        "  hash_numpy = np.array(hash)\n",
        "\n",
        "  if len(hash_numpy.shape) == 1:\n",
        "      hash_transposed = hash_numpy.reshape(-1, 1)\n",
        "  else:\n",
        "      hash_transposed = hash_numpy.T\n",
        "\n",
        "  hash_matrix = np.outer(hash_numpy, hash_transposed)\n",
        "\n",
        "  return hash_matrix\n"
      ],
      "metadata": {
        "id": "Fg1C5eOH3J9G"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def reconstruction_triplet_loss(hash_matrix, sim_matrix, triplets):\n",
        "  hash_tensor = torch.tensor(hash_matrix, dtype=torch.float32)\n",
        "  sim_tensor = torch.tensor(sim_matrix, dtype=torch.float32)\n",
        "\n",
        "  reconstruction_loss = torch.nn.functional.mse_loss(hash_tensor, sim_tensor)\n",
        "\n",
        "  anchor, positive, negative = zip(*triplets)\n",
        "\n",
        "  anchor = torch.tensor(anchor, dtype=torch.float32)\n",
        "  positive = torch.tensor(positive, dtype=torch.float32)\n",
        "  negative = torch.tensor(negative, dtype=torch.float32)\n",
        "\n",
        "  pos_distances = F.pairwise_distance(anchor, positive)\n",
        "  neg_distances = F.pairwise_distance(anchor, negative)\n",
        "\n",
        "  margin = 1.0\n",
        "\n",
        "  triplet_loss = F.relu(pos_distances - neg_distances + margin)\n",
        "  #triplet_loss += sim_matrix[torch.arange(len(triplets)), torch.arange(len(triplets))]\n",
        "\n",
        "  alpha = 0.3\n",
        "\n",
        "  loss = alpha * reconstruction_loss + (1 - alpha) * triplet_loss\n",
        "\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "OPldzmF44Xxp"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNHTrainer:\n",
        "  def __init__(self, cnnh_config) -> None:\n",
        "      self.config = cnnh_config\n",
        "      self.net = self.initialize_model()\n",
        "      self.optimizer = self.setup_optimizer()\n",
        "      self.epochs = self.config[\"epochs\"]\n",
        "      self.hashes = initalize_hashes(10000, 12)\n",
        "      self.train_labels = self.dataset_manager.load_dataset_labels(self.train_loader, self.device)\n",
        "      self.criterion = reconstruction_triplet_loss(hash_matrix, sim_matrix, anchor,\n",
        "                                                    anchor_positive_similarity,\n",
        "                                                    anchor_negative_similarity)\n",
        "\n",
        "  def initialize_model(self):\n",
        "    return self.config[\"net\"](self.config[\"bit_list\"][0])\n",
        "\n",
        "  def setup_optimizer(self):\n",
        "        optimizer_type = self.config[\"optimizer\"][\"type\"]\n",
        "        optimizer_params = self.config[\"optimizer\"][\"optim_params\"]\n",
        "\n",
        "        optimizer = optimizer_type(self.net.parameters(), **optimizer_params)\n",
        "\n",
        "        if 'weight_decay' in optimizer_params and optimizer_params['weight_decay'] > 0:\n",
        "            optimizer_params[\"weight_decay\"] = 1e-5\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "  def train(self):\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      self.net.train()\n",
        "      train_loss = self.train_epoch()\n",
        "      train_losses.append(train_loss)\n",
        "\n",
        "      if (epoch + 1) % self.config[\"test_MAP\"] == 0:\n",
        "          current_map = self.evaluate()\n",
        "          if current_map > best_map:\n",
        "              best_map = current_map\n",
        "\n",
        "      if (epoch + 1) % self.config[\"save_interval\"] == 0:\n",
        "          self.save_model_state(epoch + 1, best_map, train_losses)\n",
        "\n",
        "      if (epoch + 1) == self.epochs:\n",
        "          self.evaluate()\n",
        "          self.plot_results()\n",
        "\n",
        "  def train_epoch(self):\n",
        "    epoch_losses = []\n",
        "    for batch_index, (images, labels) in enumerate(self.train_loader):\n",
        "        torch.cuda.empty_cache()\n",
        "        images, labels = images.to(self.device), labels.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        predictions = self.net(images)\n",
        "        self.em.update(labels, predictions)\n",
        "        # Calculate loss\n",
        "        loss = self.calculate_loss(predictions, labels, batch_index)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        self.optimizer.step()\n",
        "\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "    return epoch_losses\n",
        "\n",
        "  def calculate_loss(self, prediction, targets, index):\n",
        "    loss = self.criterion(prediction, targets, index)\n",
        "\n",
        "    if self.optimizer_params.get('l2_reg', False):\n",
        "        l2_reg = torch.tensor(0.0, device=self.device)\n",
        "        for param in self.net.parameters():\n",
        "            l2_reg += torch.norm(param)\n",
        "        loss += 0.5 * self.optimizer_params['weight_decay'] * l2_reg\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def save_model_state(self, epoch, best_map, train_losses):\n",
        "    bit = self.config[\"bit_list\"]\n",
        "    save_path = f\"model_state_epoch_{epoch}_{self.config['dataset']}_{bit}.pt\"\n",
        "    torch.save(self.net.state_dict(), save_path)\n",
        "    print(f\"Model state saved at epoch {epoch}: {save_path}\")\n",
        "\n",
        "    result_dict = {\n",
        "        \"epoch\": epoch,\n",
        "        \"best_map\": best_map,\n",
        "        \"train_losses\": train_losses\n",
        "    }\n",
        "    result_path = f\"training_results_epoch_{epoch}.json\"\n",
        "    with open(result_path, 'w') as result_file:\n",
        "        json.dump(result_dict, result_file)\n",
        "    print(f\"Training results saved at epoch {epoch}: {result_path}\")"
      ],
      "metadata": {
        "id": "yXNJbkd66RRx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triplets(hashes):\n",
        "  triplets = []\n",
        "\n",
        "  for i in range(len(hashes)):\n",
        "      anchor = hashes[i]\n",
        "\n",
        "      # Select a positive sample (similar to the anchor)\n",
        "      positive_index = np.random.choice(np.where(hashes == anchor)[0])\n",
        "      positive = hashes[positive_index]\n",
        "\n",
        "      # Select a negative sample (dissimilar to the anchor)\n",
        "      negative_index = np.random.choice(np.where(hashes != anchor)[0])\n",
        "      negative = hashes[negative_index]\n",
        "\n",
        "      triplets.append((anchor, positive, negative))\n",
        "\n",
        "  return triplets"
      ],
      "metadata": {
        "id": "V9qly1gaGOjd"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnh_config_cifar = get_config_cnnh_cifar()\n",
        "\n",
        "bits = 1\n",
        "data_amount = train_labels_capped.size(0)\n",
        "\n",
        "hashes = initialize_hash(data_amount, bits)\n",
        "hash_matrix = compute_hash_matrix(hashes)\n",
        "sim_matrix = initalize_sim_matrix(bits)\n",
        "\n",
        "print(\"Hash Matrix:\")\n",
        "print(hash_matrix)\n",
        "print(\"\\nSimilarity Matrix:\")\n",
        "print(sim_matrix)\n",
        "\n",
        "triplets = generate_triplets(hashes)\n",
        "\n",
        "rec_loss = reconstruction_triplet_loss(hash_matrix, sim_matrix, triplets)\n",
        "\n",
        "print(rec_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug4Yj2wh1b2N",
        "outputId": "ad9d3a25-6d1f-40a1-89d6-925ae4702d56"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hash Matrix:\n",
            "[[ 0.59496176 -0.23058371 -0.06509267]\n",
            " [-0.23058371  0.08936516  0.02522735]\n",
            " [-0.06509267  0.02522735  0.00712156]]\n",
            "\n",
            "Similarity Matrix:\n",
            "[[25. 45. 10.]\n",
            " [45. 81. 18.]\n",
            " [10. 18.  4.]]\n",
            "tensor(403.2830)\n"
          ]
        }
      ]
    }
  ]
}